# 第 4 天

> 2025-08-28

## 学习的知识点
### 概率和统计（昨日未完成的学习内容）
- 方差与标准差
  - 学习资料：可汗学院的统计和概率课程的单元3的课程5：样本的方差与标准差

### 机器学习
- 什么是机器学习？
  - 机器学习是让计算机学习规律，从而对新的情况做出决策或预测。简单来说，机器学习的目标是让机器从经验中学习。
- 基本术语
  - 模型
    - 定义：从数据学到的规律的数学表示。它是一个函数f，输入数据，输出预测
  - 特征/属性
    - 定义：数据的可测量的属性或特性。是模型的输入
  - 标签/目标
    - 定义：在监督学习中，我们想要预测的正确答案。是模型的期望输出
  - 训练/拟合
    - 定义：通过分析数据来调整模型内部参数，使其能够做出准确预测的过程
  - 预测/推断
    - 定义：使用训练好的模型对新数据做出预测的过程
- 监督学习
  - 核心思想：模型从有标签的数据中学习“输入->输出”的映射关系
  - 典型任务
    - 回归
      - 定义：预测连续值
      - 算法举例
        - 房价预测
        - 销量预测
    - 分类
      - 定义：预测离散类别
      - 算法举例
        - 逻辑回归
        - 图像分类
        - 支持向量机（SVM）
        - 随机森林
- 无监督学习
  - 核心思想：模型从无标签的数据中获取内在结构或模式
  - 典型任务
    - 聚类
      - 定义：将数据分成有意义的簇
      - 应用举例
        - 客户分群
        - 新闻主题分组
    - 降维
      - 定义：在尽可能保留信息的前提下压缩数据
      - 应用举例
        - 数据可视化
        - 数据预处理
- 强化学习
  - 核心思想：智能体在环境中通过尝试和错误来学习，根据获得的奖励调整策略，以实现长期累计奖励最大化
  - 关键要素
    - Agent：做决策的程序
    - Environment：Agent交互的世界
    - Reward：环境对Agent行动的反馈信号
  - 应用举例
    - AlphaGo
    - 机器人控制
    - 游戏AI
    - 广告自动化投放策略优化
- 典型的工作流程
  - 数据收集
  - 数据清洗：处理缺失值、异常值、格式不一致
  - 特征工程：利用领域知识从原始数据中提取特征。这是机器学习项目成败的关键
  - 模型训练：选择算法，在训练集上拟合模型
  - 模型评估：在测试集上评估模型性能（如准确率、精确率）
  - 部署上线
  - 监控与迭代


## 遇到的问题和解决方案

### 不理解标准差有时候除以 N 有时候除以 N-1

> 解析

简单答案是：
*   **除以 N**：当你拥有**整个总体**的所有数据时。这得到的是**总体标准差（Population Standard Deviation）**，符号是 σ。
*   **除以 N-1**：当你只有总体的一个**样本**，并想用这个样本去**估计**总体标准差时。这得到的是**样本标准差（Sample Standard Deviation）**，它是总体标准差的一个**无偏估计量**。

下面，我用一个绝妙的比喻让你彻底明白为什么是 **N-1**。

---

### **核心比喻：工厂与质检员**

想象你是一家巨型工厂的质量总监。

1.  **总体 vs. 样本**：
    *   **总体**： 工厂生产的所有产品（比如100万个小螺丝）。
    *   **样本**： 你从生产线上随机抽取一小批产品（比如100个螺丝）来进行测量。你不可能测量每一个螺丝。

2.  **你的目标**：
    你想知道**所有产品（总体）** 尺寸的波动有多大，即求**总体标准差 σ**。

3.  **问题所在**：
    你只有100个螺丝（样本）的数据。你只能用这100个数据来**猜**（估计）那100万个螺丝的波动情况。

4.  **陷阱：低估的均值**
    你没有总体的真实均值（μ），只能用样本的均值（x̄）来代替。
    *   样本的均值（x̄）是为了**完美拟合你当前样本**而计算出来的。
    *   计算方差时，我们看的是每个数据点与均值的偏差 `(x - x̄)`。
    *   **关键洞察**：**样本数据点相对于样本均值 x̄ 的偏差，通常会小于相对于总体真实均值 μ 的偏差。**
    *   因为 x̄ 是这些数据的中心，数据自然会更“抱团”地围绕在 x̄ 周围，而不是围绕在 μ 周围。

    **这会导致你用公式 `Σ(x - x̄)² / N` 算出的方差，系统地低估了真正的总体方差。**

5.  **解决方案：贝塞尔校正（Bessel's Correction）**
    为了纠正这种系统性的低估，我们需要把分母调小一点。数学上可以证明，将分母从 **N 减小到 N-1**，可以完美地补偿这个低估效应，使得计算结果 `Σ(x - x̄)² / (N-1)` 成为总体方差 σ² 的一个**准确（无偏）的估计**。

    **为什么是 N-1？**
    *   你可以把 **N-1** 理解为**自由度**。
    *   在你计算完样本均值（x̄）之后，在这 N 个数据点中，**只有 N-1 个数据是可以“自由变化”的**。
    *   例如：你的样本有3个数据：[a, b, c]。你计算出的均值 x̄ = 5。
        现在，如果我让你随便改变这些数据，但均值必须保持是5。
        你可以自由地设定 a 和 b 的值（比如 a=4, b=6），但此时 c 的值就被固定了（c必须等于 `5*3 - 4 - 6 = 5`），无法自由变化。
    *   所以，用于估计波动的有效独立信息点，是 **N-1** 个。

#### **一张表彻底分清**

| | **总体标准差 (σ)** | **样本标准差 (s)** |
| :--- | :--- | :--- |
| ****目的** | **描述**你手头所有数据的离散程度。 | **估计**一个更大总体的离散程度。 |
| ****数据** | 你拥有**全部**数据。 <br>（例：全班50人的成绩） | 你只有**一部分**数据（样本）。 <br>（例：从全市抽200人调查收入） |
| **公式** | `σ = √[ Σ(x - μ)² / N ]` | `s = √[ Σ(x - x̄)² / (N - 1) ]` |
| **分母** | **N** (数据点的总数) | **N-1** (自由度) |
| **何时使用** | 你的目标就是分析当前这个数据集。 | 你的目标是通过样本推断总体的性质。 |

## 课后习题
### **1. “期望值和算术平均值的区别是什么？”**

这是一个经典问题。它们的公式看起来很像，但本质完全不同。

**一句话概括**：
*   **算术平均值** 是对 **过去** 已发生数据的 **总结**。
*   **期望值** 是对 **未来** 所有可能结果的 **预测**。

让我们用一个简单的比喻——**掷骰子**：

| | **算术平均值 (Average/Mean)** | **期望值 (Expected Value)** |
| :--- | :--- | :--- |
| ****对象** | **已发生** 的数据集。<br>（例：你**刚才**掷了10次骰子，结果是 [1, 3, 5, 2, 6, ...]） | **随机变量** 所有**可能**的结果。<br>（例：一个**公平骰子**本身，它的可能结果是1到6） |
| ****计算** | $\text{平均值} = \frac{1 + 3 + 5 + 2 + 6 + ...}{10}$ <br>**公式**：$\bar{x} = \frac{1}{n}\sum_{i=1}^{n} x_i$ | $\text{期望值} = 1*\frac{1}{6} + 2*\frac{1}{6} + ... + 6*\frac{1}{6} = 3.5$ <br>**公式**：$E[X] = \sum x_i P(x_i)$ |
| ****本质** | **描述性统计**。它是一个**确定的数**，描述你**那10次**实验的平均结果。 | **概率论概念**。它是一个**理论值**，描述这个随机过程（掷公平骰子）**固有的、长期的**平均属性。 |
| ****关系** | **大数定律**：随着实验次数（n）不断增加，**算术平均值会越来越接近期望值**。你掷骰子的次数越多，平均得分就越接近3.5。 |

**所以，期望值是“上帝视角”的理论真值，而算术平均值是我们从有限数据中计算出的、对那个真值的估计。**

---

### **2. “方差公式为什么要把差值平方？”**

这是一个非常深刻的问题。之所以不直接用 `|x - μ|`（绝对差值），而要用 `(x - μ)²`（平方差值），主要有三个核心原因：

1.  **数学性质更优（最主要原因）**：
    *   **可导性**：平方函数是**光滑可导的**，而绝对值函数在0点处不可导。这个性质在机器学习中至关重要，因为我们需要用**梯度下降**等优化算法求极值（比如最小化方差），可导性保证了计算的高效和稳定。
    *   **分解性**：方差具有一系列优美的数学性质。例如，**总方差 = 组内方差 + 组间方差**。这种可加性在统计分析中非常强大，但如果使用绝对值，就没有这么简洁的分解公式。

2.  **放大较大偏差**：
    平方操作会**赋予离群值更大的权重**。一个距离均值2个单位的点，对平方差的贡献是4，而一个距离4个单位的点，贡献是16。这意味着方差对极端值更敏感，这通常是我们想要的，因为我们要识别并尽量减少那些“错得离谱”的预测。

3.  **与欧氏距离关联**：
    在几何上，方差的最小值点（即均值）是数据点在**欧几里得距离**（我们最常用的距离定义）意义下的中心点。最小化平方差等价于最小化所有数据点到中心点的欧氏距离之和。

**当然，使用绝对值（即平均绝对差）在数学上也是可以的，这个指标叫做** **平均绝对误差（MAE）**。它在某些场景下甚至更有优势（比如对异常值不敏感）。但在理论推导和许多算法的基础中，方差（MSE）因其优异的数学性质而成为更核心的概念。

---

### **3. “在投资中，如何用均值/标准差衡量收益和风险？”**

这是现代金融学的基石——**马克维茨的投资组合理论**。其核心思想就是用均值和标准差来量化投资的两个核心要素：

| | **均值 (Mean / Expected Return)** | **标准差 (Standard Deviation)** |
| :--- | :--- | :--- |
| ****代表什么** | **期望收益率** | **风险（波动率）** |
| ****如何理解** | 衡量一项投资**长期来看**平均能给你带来多少回报。 | 衡量投资回报的**不确定性**或**波动程度**。 |
| ****投资者视角** | **“收益”**：我希望能赚钱，所以偏好高均值。 | **“风险”**：我讨厌亏损，所以偏好低标准差。因为标准差大意味着：<br>1. 可能赚得更多，但也**可能亏得更多**。<br>2. 收益**不稳定**，心里没底。 |

**实战应用：**

1.  **比较单一资产**：
    *   **股票A**：年均收益10%，标准差15%。
    *   **国债B**：年均收益3%，标准差2%。
    *   **分析**：股票A收益更高（均值10% > 3%），但风险也大得多（标准差15% >> 2%）。你的选择取决于你的**风险偏好**。

2.  **构建投资组合（分散风险）**：
    现代金融学最伟大的发现之一是：将**不同步涨跌**（相关性低）的资产组合起来，可以在**不降低太多期望收益的情况下，显著降低整体风险（标准差）**。
    *   **例子**：假设你有两个股票，期望收益都是8%。
        *   如果它们完全同涨同跌，组合的标准差依然是15%。
        *   但如果它们一个涨另一个就跌（负相关），组合的标准差可能会**大幅降低到5%**。
    *   **这就是“不要把所有鸡蛋放在一个篮子里”的数学表达**。组合的期望收益是各个资产收益的加权平均，但组合的风险（标准差）却**不是**简单的加权平均，它还与资产间的相关性有关。

**结论**：
在投资中，**均值（期望收益）和标准差（风险）** 就像一枚硬币的两面。投资者的核心任务就是在“高收益高风险”和“低收益低风险”之间找到最适合自己承受能力的那个平衡点，并通过分散化投资来优化这个平衡。

## 心得体会
